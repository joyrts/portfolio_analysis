{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F01GLqqCIcf1"
      },
      "outputs": [],
      "source": [
        "!pip install newsapi-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance"
      ],
      "metadata": {
        "id": "ShSknuW9IhR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment"
      ],
      "metadata": {
        "id": "o1t9emCCIjyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from newsapi import NewsApiClient\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from scipy.optimize import minimize"
      ],
      "metadata": {
        "id": "l-pySCjqInAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the tickers of the assets to include in the portfolio\n",
        "tickers = ['AAPL', 'GOOG', 'AMZN', 'META', 'TSLA']"
      ],
      "metadata": {
        "id": "gRqCp4CbIp5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NEWS_API_KEY = '08f2c33f0f9b4dfa9a907afc725bb0c7'\n",
        "# Initialize the News API client and the VADER sentiment analyzer\n",
        "newsapi = NewsApiClient(api_key= NEWS_API_KEY)\n",
        "analyzer = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "ZuxierksIsmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the date range for the news articles\n",
        "date_from = '2023-03-30'\n",
        "date_to = '2023-04-30'"
      ],
      "metadata": {
        "id": "pwc-qhcCI7SR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prices = yf.download(tickers, period='max')['Adj Close']"
      ],
      "metadata": {
        "id": "1cSoxMyvIyFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to fetch the news articles and calculate their sentiment scores\n",
        "def get_sentiment_scores(keyword, date_from, date_to):\n",
        "    articles = newsapi.get_everything(q=keyword, from_param=date_from, to=date_to, language='en')\n",
        "    scores = [analyzer.polarity_scores(article['title'])['compound'] for article in articles['articles']]\n",
        "    return scores"
      ],
      "metadata": {
        "id": "6z-CvusBI0Se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch the sentiment scores for each stock\n",
        "sentiment_scores = {}\n",
        "for ticker in tickers:\n",
        "    keyword = ticker + ' stock'\n",
        "    scores = get_sentiment_scores(keyword, date_from, date_to)\n",
        "    sentiment_scores[ticker] = np.mean(scores)\n"
      ],
      "metadata": {
        "id": "BeLgA0pMI4x-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the expected returns and covariance matrix of the assets\n",
        "returns = np.log(prices / prices.shift(1)).mean()\n",
        "cov_matrix = np.log(prices / prices.shift(1)).cov()"
      ],
      "metadata": {
        "id": "CGh_nD2zJQeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the objective function to minimize\n",
        "def neg_sharpe_ratio(weights, returns, cov_matrix, sentiment_scores):\n",
        "#    print('weights:', weights)\n",
        "#    print('returns:', returns.values)\n",
        "#    print('sentiment_scores:', list(sentiment_scores.values))\n",
        "#    print('sentiment_scores:', list(sentiment_scores.values()))\n",
        "    portfolio_return = np.dot(weights, returns.values) + np.dot(weights, list(sentiment_scores.values()))\n",
        "    portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
        "    sharpe_ratio = portfolio_return / portfolio_volatility\n",
        "    return -sharpe_ratio"
      ],
      "metadata": {
        "id": "q42F-8qLJTlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def neg_sharpe_ratio_wosenti(weights, returns):\n",
        "    port_returns = np.sum(returns.mean() * weights) * 252\n",
        "    port_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix * 252, weights)))\n",
        "    return -port_returns / port_volatility"
      ],
      "metadata": {
        "id": "yLnp0gR6JWKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the constraints of the optimization problem\n",
        "constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})"
      ],
      "metadata": {
        "id": "6SCPjLo6JYij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the bounds of the optimization problem\n",
        "bounds = tuple((0, 1) for _ in range(len(tickers)))"
      ],
      "metadata": {
        "id": "a0BWELmyJhYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Solve the optimization problem to find the optimal portfolio weights\n",
        "initial_weights = [1 / len(tickers) for _ in range(len(tickers))]\n",
        "opt_result = minimize(neg_sharpe_ratio, initial_weights, args=(returns, cov_matrix, sentiment_scores), method='SLSQP', bounds=bounds, constraints=constraints)\n"
      ],
      "metadata": {
        "id": "H_ZkENqyJjhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('opt_result:', np.round(opt_result.x*100,1), '%')\n",
        "opt_weights = opt_result.x\n",
        "print(np.round(-opt_result.fun,2))"
      ],
      "metadata": {
        "id": "has4OFyxJmB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the optimal portfolio weights and the maximum Sharpe ratio\n",
        "print('Optimal portfolio weights:', opt_weights)\n",
        "print('Maximum Sharpe ratio:', -opt_result.fun)"
      ],
      "metadata": {
        "id": "UAHllarjJyJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#without sentiments\n",
        "opt_result_without_sentiment = minimize(neg_sharpe_ratio_wosenti, initial_weights, args=returns, method='SLSQP', bounds=bounds, constraints=constraints)\n",
        "\n"
      ],
      "metadata": {
        "id": "J9dVsj8hJpO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('opt_result_without_sentiment:', np.round(opt_result_without_sentiment.x*100,2), '%')\n",
        "opt_weightswo_sentiment = opt_result_without_sentiment.x\n",
        "print(np.round(-opt_result_without_sentiment.fun,2))"
      ],
      "metadata": {
        "id": "RZGdmb0-J2XK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}